---
title: 'Deliverable #1 Project Proposal'
author: "Group #1: Holland Robinson, Vu Nguyen, Kathryn Mioduszewski, Pranav Patil, Sreechandana Anumolu, Yash Ghate"
date: "4/14/2023"
output: 
  html_document:
    toc: true
    theme: readable
    highlight: tango
    code_folding: show
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## What Data Will You Use?
This dataset details used car data. The Y variable is whether or not the car is sold. The X variables include attributes like car type, mileage, make, and model, among other attributes.

```{r}
car <- read.csv("Car_data (1).csv")
```

## Business Question
With this data, you can build an algorithm to predict what attributes influence the sale of a car. This is relevant to used car dealerships when choosing whether you would accept this car from the seller to subsequently sell. 

## Preliminary Exploration and Cleaning of Data
```{r}
car$Sales_ID <- NULL
car$age <- max(car$year) - car$year
car$name <- as.factor(car$name)
car$State <- as.factor(car$State)
car$Region <- as.factor(car$Region)
car$seller_type <- as.factor(car$seller_type)
car$transmission <- as.factor(car$transmission)
car$fuel <- as.factor(car$fuel)
car$owner <- as.factor(car$owner)
car$sold <- as.factor(car$sold)
car$name <- ifelse(car$name == "Opel" | car$name == "Ashok" | car$name == "MG" | car$name == "Daewoo" | car$name == "Kia" | car$name == "Ambassador" | car$name == "Isuzu" | car$name == "Land" | car$name == "Force","Other", car$name)

car$City <- ifelse(car$City == "New York City" | car$City == "Los Angeles" | car$City == "Seattle" | car$City == "Chicago" | car$City == "Boston" | car$City == "Washington" | car$City == "Philadelphia" | car$City == "Charlotte" | car$City == "Miami" | car$City == "Detroit"  , car$City, "Other")

carv1 <- as.data.frame(model.matrix(~.-1,car))

str(car)
summary(carv1)

```

#Normalize Data 
```{r}
normalize <- function(x){
  return((x-min(x))/(max(x)-min(x)))
}

car_norm <- as.data.frame(lapply(carv1, normalize))

summary(car_norm)

```

# Split Data 
```{r}

set.seed(12345)
test_rows <- sample(1:nrow(car_norm), 0.5*nrow(car_norm))
car_test <- car_norm[test_rows, ]
car_train <- car_norm[-test_rows, ]

#Data Cleaning & creating test and train for KNN
carknn_test <- car_norm[test_rows,-match("soldY",names(car_norm))]
carknn_train <- car_norm[-test_rows,-match("soldY",names(car_norm))]
carknn_test_labels <- car_norm[test_rows,"soldY"]
carknn_train_labels <- car_norm[-test_rows,"soldY"]

#Data Cleaning and creating test and train for Decision Tree
test_set <- sample(1:nrow(car), 0.5*nrow(car))
cardt_train <- car[-test_rows, ]
cardt_test <- car[test_rows, ]
```
# Regression Model
```{r}

# %%%%%  MODEL %%%%%% 
basemodel <- glm(soldY ~., data = car_train, family = "binomial")
#summary(basemodel)

# %%%%% Predict %%%%%
library(caret)
carpred <- predict(basemodel, car_test, type = "response")
car_binary_pred <- ifelse(carpred >= 0.5, 1, 0)
#table(car_binary_pred)
confusionMatrix(as.factor(car_binary_pred), as.factor(car_test$soldY))

```
# KNN Model
```{r}
#Build Model
library(class)
knn_model <- knn(carknn_train,carknn_test,carknn_train_labels,k=40,prob= TRUE)

## Evaluate Model
library(caret)
confusionMatrix(as.factor(knn_model), as.factor(carknn_test_labels),positive = "1")

```
# ANN Model
```{r}
library(neuralnet)

#BUILDING THE MODEL
model_ann1 <- neuralnet(soldY ~., data = car_train, hidden = 5,2) 
plot(model_ann1)
saveRDS(model_ann1, file = 'model_ann1.rds')

# Predicting the ANN model 
model_ann_1predict <- predict(model_ann1,car_test)
model_ann1bin <- ifelse(model_ann_1predict >= 0.25,1,0)

#EVALUATING 
library(caret)
confusionMatrix(as.factor(model_ann1bin), as.factor(car_test$soldY), positive = "1")

```

# DECISION TREE
```{r}
library(C50)

#BUILDING THE MODEL
set.seed(12345)
cartree <- C5.0(as.factor(sold)~., data = cardt_train)
plot(cartree)
summary(cartree)

#PREDICTING THE MODEL
cartreepred <- predict(cartree, cardt_test)

#EVALUATING THE MODEL
confusionMatrix(as.factor(cartreepred),as.factor(cardt_test$sold), positive = "Y")
```

# RANDOM FOREST
```{r}
library(randomForest)
#Predict the RF Model 
carforest <- randomForest(as.factor(soldY) ~. , data = car_train)
summary(carforest)
randomForest::varImpPlot(carforest)

#Evaluate and Predict 
carrfpredict <- predict(carforest, car_test)
summary(carrfpredict)
confusionMatrix(as.factor(carrfpredict), as.factor(car_test$soldY), positive = "1")

```
# Stacked Model 
```{r}
# COMBINING MODELS
stacked_car <- data.frame(log_pred = carpred, KNN = knn_model, ANN = model_ann_1predict, DT_pred = cartreepred, rf_pred = carrfpredict,y = car_test$soldY)

#summary(stacked_car)

# SPLITING THE DATA
set.seed(1234)
test_set1 <- sample(1:nrow(stacked_car), 0.3*nrow(stacked_car)) 
cars_train_st <- stacked_car[-test_set1, ]
cars_test_st <- stacked_car[test_set1, ]

```
# Building Stacked Model's Decision tree
```{r}

library(C50)
stackedtree <- C5.0(as.factor(y) ~., data = cars_train_st)
plot(stackedtree)

#Predict and Evaluate Model 
library(caret)
stackedpredict <- predict(stackedtree,cars_test_st)
confusionMatrix(as.factor(stackedpredict), as.factor(cars_test_st$y), positive = "1")

```
# Cost Matrix 
```{r}
error_cost = matrix(c(0,1,4,0), nrow =2) 
error_cost

errormodel <- C5.0(as.factor(y)~., data = cars_train_st,costs = error_cost)
prederror <- predict(errormodel, cars_test_st)
summary(prederror)
confusionMatrix(as.factor(prederror), as.factor(cars_test_st$y), positive = "1")

```
# IMPROVED DECISION TREE
```{r}
library(caret)
set.seed(12345)
ctrl <- trainControl(method = "cv", number = 10, selectionFunction = "oneSE")

#ctrl <- trainControl(selectionFunction = "oneSE")
grid <- expand.grid(.model="tree", .trials= c(1,5,10,15,20), .winnow="FALSE")

train_model_dt <- train(as.factor(soldY) ~., data = car_train, method="C5.0", metric="Kappa", trControl=ctrl, tuneGrid= grid)

predict_train_dt <- predict(train_model_dt, car_test)
confusionMatrix(as.factor(predict_train_dt), as.factor(car_test$soldY), positive="1")
```
# KNN TUNING  
```{r}
library(caret)

# Define the tuning grid
grid_knn <- expand.grid(k = seq(5,60,5))

# Define the training control
ctrl_knn <- trainControl(method = "cv", number = 4, selectionFunction = "oneSE")

# Train the KNN model
set.seed(12345)
train_model_knn <- train(as.factor(soldY)~ ., data = car_train, method = "knn", metric="Kappa", trControl = ctrl_knn, tuneGrid = grid_knn, preProcess=c("center","scale"))

#train_model_knn
#summary(train_model_knn)

# Make predictions on the test set
predict_train_knn <- predict(train_model_knn, car_test)

# Generate confusion matrix
confusionMatrix(as.factor(predict_train_knn), as.factor(car_test$soldY), positive = "1")
```
#RANDOM FOREST TUNING 
```{r}
# Define the training control
ctrl_rf <- trainControl(method = "cv", number = 3, selectionFunction = "oneSE")

# Define the tuning grid
grid_rf <- expand.grid(.mtry = c(2, 4, 8))

set.seed(12345)
train_model_rf <- train(as.factor(soldY) ~ ., data = car_train, method = "rf", metric = "Kappa", trControl = ctrl_rf, tuneGrid = grid_rf)

train_model_rf

predict_train_rf <- predict(train_model_rf, car_test)

confusionMatrix(as.factor(predict_train_rf), as.factor(car_test$soldY), positive = "1")
```
## ANN tuning
```{r}
midmodel <- neuralnet(soldY ~ ., data = car_train, hidden = 1, stepmax = 1e6)

plot(midmodel)

midpred <- predict(midmodel, car_test)
midbin <- ifelse(midpred >= .5, 1, 0)

confusionMatrix(as.factor(midbin), as.factor(car_test$soldY), positive = "1")

```
# Logistics Regression Tuning 
```{r}
library(caret)

# Define the training control
ctrl_lr <- trainControl(method = "cv", number = 10, selectionFunction = "oneSE")

# Define the tuning grid
grid_lr <- expand.grid(
  .alpha = c(0, 0.25, 0.5, 0.75, 1),
  .lambda = c(0.0001, 0.001, 0.01, 0.1, 1)
)

# Train the logistic regression model
set.seed(12345)
train_model_lr <- train(as.factor(soldY) ~ ., data = car_train, method = "glmnet", family = "binomial", metric = "Kappa", trControl = ctrl_lr, tuneGrid = grid_lr, preProcess = c("center", "scale"))

# Make predictions on the test set
predict_train_lr <- predict(train_model_lr, car_test)

# Generate confusion matrix
confusionMatrix(as.factor(predict_train_lr), as.factor(car_test$soldY), positive = "1")

```

## Combining Tunes Models

# Creating Combined-Tuned Data Frame
```{r}
# Logistic Regression - predict_train_lr
# KNN - predict_train_knn
# ANN - midpred
# Decision Tree - predict_train_dt
# randomForest - predict_train_rf
# Combined Model - all of them together

combined_tune_model <- data.frame(predict_train_lr, predict_train_knn, midpred, predict_train_dt,  predict_train_rf,carknn_test_labels)

colnames(combined_tune_model) <- c("Logistical Regression", "KNN", "ANN", " Decision Tree", "Random Forest", "actuals")

summary(combined_tune_model)

```

#Test and Train the Combined-Tuned
```{r}
set.seed(12345)
test_combined_tune <- sample(1:nrow(combined_tune_model), 0.3*nrow(combined_tune_model))

# Create a train set and test set
#First the predictors - all columns except the actuals column
combined_tune_test <- combined_tune_model[test_combined_tune, -match("actuals",names(combined_tune_model))]
combined_tune_train <- combined_tune_model[-test_combined_tune, -match("actuals",names(combined_tune_model))]

#Now the response (aka Labels) - only the actuals column
combined_tune_train_labels <- combined_tune_model[-test_combined_tune, "actuals"]
combined_tune_test_labels <- combined_tune_model[test_combined_tune, "actuals"]

```

#Decision Tree with Combined-Tuned Predictions
```{r}
combined_tune_tree <- C5.0(as.factor(combined_tune_train_labels) ~., data = combined_tune_train)

plot(combined_tune_tree)

summary(combined_tune_tree)

combined_tune_pred <- predict(combined_tune_tree, combined_tune_test)

confusionMatrix(as.factor(combined_tune_pred), as.factor(combined_tune_test_labels), positive = "1")

```

## Cost Matrix of the Combined-Tuned Model
```{r}
error_cost <- matrix(c(0, 1, 10, 0), nrow = 2)

#error_cost

error_tune_model <- C5.0(as.factor(combined_tune_train_labels) ~ ., data = combined_tune_train, costs = error_cost)
error_tune_pred <- predict(error_tune_model, combined_tune_test)
confusionMatrix(as.factor(error_tune_pred), as.factor(combined_tune_test_labels), positive = "1")
```
